% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nestedCV.R
\name{regular_nestedCV}
\alias{regular_nestedCV}
\title{Regular nested cross validation for feature selection and parameter tuning}
\usage{
regular_nestedCV(
  train.ds = NULL,
  validation.ds = NULL,
  label = "class",
  method.model = "classification",
  is.simulated = TRUE,
  ncv_folds = c(10, 10),
  param.tune = FALSE,
  learning_method = "rf",
  xgb.obj = "binary:logistic",
  importance.algorithm = "ReliefFequalK",
  wrapper = "relief",
  inner_selection_percent = 0.2,
  inner_selection_positivescores = TRUE,
  relief.k.method = "k_half_sigma",
  tuneGrid = NULL,
  num_tree = 500,
  verbose = FALSE
)
}
\arguments{
\item{train.ds}{A training data frame with last column as outcome}

\item{validation.ds}{A validation data frame with last column as outcome}

\item{label}{A character vector of the outcome variable column name.}

\item{method.model}{Column name of outcome variable (string), classification or regression. If the analysis goal is classification make the column a factor type.
For regression, make outcome column numeric type.}

\item{is.simulated}{A TRUE or FALSE character for data type}

\item{ncv_folds}{A numeric vector to indicate nested cv folds: c(k_outer, k_inner)}

\item{param.tune}{A TRUE or FALSE character for tuning parameters}

\item{learning_method}{Name of the method: glmnet/xgbTree/rf}

\item{xgb.obj}{Name of xgboost algorithm}

\item{importance.algorithm}{A character vestor containing a specific importance algorithm subtype}

\item{wrapper}{feature selection algorithm including: rf, glmnet, t.test, centrality methods (PageRank, Katz,
EpistasisRank, and EpistasisKatz from Rinbix packages), ReliefF family, and etc.}

\item{inner_selection_percent}{= .2 Percentage of features to be selected in each inner fold.}

\item{inner_selection_positivescores}{A TRUE or FALSE character to select positive scores (if the value is False, use the percentage method).}

\item{relief.k.method}{A character of numeric to indicate number of nearest neighbors for relief algorithm.
Possible characters are: k_half_sigma (floor((num.samp-1)*0.154)), m6 (floor(num.samp/6)),}

\item{tuneGrid}{A data frame with possible tuning values. The columns are named the same as the tuning parameters.
This caret library parameter, for more information refer to  http://topepo.github.io/caret/available-models.html.
myopic (floor((num.samp-1)/2)), and m4 (floor(num.samp/4))}

\item{num_tree}{Number of trees in random forest and xgboost methods}

\item{verbose}{A flag indicating whether verbose output be sent to stdout}
}
\value{
A list with:
\describe{
\item{cv.acc}{Training data accuracy}
\item{Validation}{Validation data accuracy}
\item{Features}{number of variables detected correctly in nested cross validation}
\item{Train_model}{Traing model to use for validation}
\item{Elapsed}{total elapsed time}
}
num.samples <- 100
num.variables <- 100
pct.signals <- 0.1
label <- "class"
sim.data <- createSimulation(num.samples = num.samples,
num.variables = num.variables,
pct.signals = pct.signals,
sim.type = "mainEffect",
label = label,
verbose = FALSE)
rnCV.results <- regular_nestedCV(train.ds = sim.data$train,
validation.ds = sim.data$holdout,
label = label,
is.simulated = TRUE,
ncv_folds = c(10, 10),
param.tune = FALSE,
learning_method = "rf",
importance.algorithm = "ReliefFbestK",
num_tree = 500,
verbose = FALSE)
}
\description{
Regular nested cross validation for feature selection and parameter tuning
}
\seealso{
Other nestedCV: 
\code{\link{consensus_nestedCV}()},
\code{\link{functionalDetectionStats}()}
}
\concept{nestedCV}
